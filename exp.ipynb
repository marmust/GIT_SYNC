{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pickle\n",
    "import threading\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exquisite acronym explanation (also sounds like lean):\n",
    "# R - recurrent\n",
    "# E - embedding\n",
    "# A - approximation\n",
    "# N - network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings mode\n",
    "model_file = fr\"./embedding_models/wiki_model3.model\"\n",
    "embeddings_model = Word2Vec.load(model_file)\n",
    "vector_size = embeddings_model.vector_size\n",
    "window = embeddings_model.window\n",
    "\n",
    "# neural net settings\n",
    "segment_size = 6\n",
    "input_size = vector_size * segment_size\n",
    "output_size = vector_size * segment_size\n",
    "\n",
    "# dataset\n",
    "train_dataset_path = fr\"./datasets/wiki_dump_train.txt\"\n",
    "test_dataset_path = fr\"./datasets/wiki_dump_test.txt\"\n",
    "unique_examples_train = 4096 * 8 * 3\n",
    "unique_examples_test = 4096\n",
    "lerp_steps = 4\n",
    "\n",
    "# training\n",
    "epochs = 64\n",
    "initial_lr = 0.0003\n",
    "final_lr = 0.00003\n",
    "gamma = (final_lr / initial_lr) ** (1 / epochs)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "batch_size = 1024#8#16#32#56#1024 * 1\n",
    "\n",
    "# pytorch\n",
    "run_device = torch.device(\"cuda\")\n",
    "storage_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class REAN_block(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(REAN_block, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size * 2, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 1200)\n",
    "        self.fc3 = nn.Linear(1200, 1200)\n",
    "        self.fc4 = nn.Linear(1200, output_size)\n",
    "\n",
    "    def forward(self, prev_block: torch.Tensor, fresh_input: torch.Tensor) -> torch.Tensor:\n",
    "        batch_given = prev_block.shape[0]\n",
    "        \n",
    "        prev_block = prev_block.view(batch_given, segment_size * vector_size)\n",
    "        fresh_input = fresh_input.view(batch_given, segment_size * vector_size)\n",
    "        \n",
    "        x = torch.cat((prev_block, fresh_input), dim=1)\n",
    "        \n",
    "        x /= 5\n",
    "        \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        x *= 5\n",
    "        \n",
    "        # reshape so next block will have correct shape\n",
    "        x = x.view(batch_given, segment_size, vector_size)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\CONDA_VENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# intake dim: (batch, segment_size, vector_size) x 1\n",
    "# output dim: (batch, segment_size, vector_size) x 1\n",
    "class REAN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(REAN, self).__init__()\n",
    "        \n",
    "        self.block1 = REAN_block(input_size, output_size)\n",
    "        self.block2 = REAN_block(input_size, output_size)\n",
    "        self.block3 = REAN_block(input_size, output_size)\n",
    "        self.block4 = REAN_block(input_size, output_size)\n",
    "        self.block5 = REAN_block(input_size, output_size)\n",
    "        self.block6 = REAN_block(input_size, output_size)\n",
    "        self.block7 = REAN_block(input_size, output_size)\n",
    "        self.block8 = REAN_block(input_size, output_size)\n",
    "\n",
    "    def forward(self, current_segment: torch.Tensor) -> torch.Tensor:\n",
    "        # keep x's clone from the start so the blocks get fresh input\n",
    "        self.fresh_input = current_segment.clone()\n",
    "        \n",
    "        current_segment = self.block1(current_segment, self.fresh_input)\n",
    "        current_segment = self.block2(current_segment, self.fresh_input)\n",
    "        current_segment = self.block3(current_segment, self.fresh_input)\n",
    "        current_segment = self.block4(current_segment, self.fresh_input)\n",
    "        current_segment = self.block5(current_segment, self.fresh_input)\n",
    "        current_segment = self.block6(current_segment, self.fresh_input)\n",
    "        current_segment = self.block7(current_segment, self.fresh_input)\n",
    "        current_segment = self.block8(current_segment, self.fresh_input)\n",
    "        \n",
    "        return current_segment\n",
    "\n",
    "net = REAN(input_size)\n",
    "net.to(run_device)\n",
    "optimizer = optimizer(net.parameters(), lr=initial_lr)\n",
    "scheduler = scheduler(optimizer, T_max=epochs, eta_min=final_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(start: float, end: float, progress: float) -> float:\n",
    "    return start + progress * (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_chunk(path: str, num_words: int, seek_start: int, sep: str = \" \") -> tuple[list, bool, int]:\n",
    "    \"\"\"\n",
    "    function to load a chunk of the dataset where the words are separated by \"sep\" into a list\n",
    "    \n",
    "    parameters:\n",
    "        path (str): path to the dataset txt file\n",
    "        num_words (int): number of words to load\n",
    "        seek_start (int): start char to pull words from\n",
    "        sep (str, optional): separator in the dataset, defaults to space \" \"\n",
    "    \n",
    "    returns:\n",
    "        list: list of strings (loaded words), is EOF hit, seek position to move 1 word forward\n",
    "    \"\"\"\n",
    "    \n",
    "    # some safety checks so later code looks cleaner\n",
    "    num_words = max(0, num_words)\n",
    "    seek_start = max(0, seek_start)\n",
    "    \n",
    "    words = []\n",
    "    current_word_idx = 0\n",
    "    word_buffer = \"\"\n",
    "    current_seek = seek_start\n",
    "    next_seek = 0\n",
    "    first_word_flag = True\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        file.seek(seek_start)\n",
    "        \n",
    "        # loop over all chars after seek_start\n",
    "        while True:\n",
    "            char = file.read(1)\n",
    "            current_seek += 1\n",
    "            \n",
    "            # end of file, return whatever has been collected immediately\n",
    "            if not char:\n",
    "                return words, True, next_seek\n",
    "            \n",
    "            # is a separator between words hit\n",
    "            if char == sep or char.isspace():\n",
    "                if word_buffer:\n",
    "                    if current_word_idx < num_words:\n",
    "                        words.append(word_buffer)\n",
    "                    \n",
    "                    current_word_idx += 1\n",
    "                    word_buffer = \"\"\n",
    "                \n",
    "                if current_word_idx >= num_words:\n",
    "                    break\n",
    "                \n",
    "                # the first word is covered, this is where the next chunk is going to be loaded from\n",
    "                if first_word_flag:\n",
    "                    first_word_flag = False\n",
    "                    next_seek = current_seek\n",
    "            else:\n",
    "                word_buffer += char\n",
    "\n",
    "    return words, False, next_seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence: list[str], model: Word2Vec, default: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    encodes all words in a given list to corresponding vectors in given model.\n",
    "    words not found in the model will be given a vector with \"default\" value\n",
    "    \n",
    "    parameters:\n",
    "        sentence (list): list of strings (words)\n",
    "        model (Word2Vec): model to use when encoding\n",
    "        default (int): fill vector with this value if word is not found in model\n",
    "    \n",
    "    returns:\n",
    "        np.array: 2d array with dim1 = len(sentence) and dim2 = model.vector_size\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate inital array with default values\n",
    "    vectorized = np.ones((len(sentence), model.vector_size)) * default\n",
    "    \n",
    "    # loop over every word in list\n",
    "    for current_word, current_word_idx in zip(sentence, range(len(sentence))):\n",
    "        # only add correct values if word is in model, otherwise leave as default\n",
    "        if current_word in model.wv:\n",
    "            vectorized[current_word_idx] *= 0\n",
    "            vectorized[current_word_idx] += model.wv[current_word]\n",
    "    \n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devectorize_sentence(vectorized_sentence: np.array, model: Word2Vec) -> list:\n",
    "    \"\"\"\n",
    "    decodes vectors into nearest word found in model\n",
    "    \n",
    "    parameters:\n",
    "        vectorized_sentence (np.array): 2d arrat with vectors of words to be decoded\n",
    "        model (Word2Vec): model to use when decoding\n",
    "    \n",
    "    returns:\n",
    "        list: list of strings (words) whos vectors most closely match those provided\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # go over all words and find closest match in model\n",
    "    for current_word in vectorized_sentence:\n",
    "        result.append(model.wv.similar_by_vector(current_word)[0][0])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(suspected_tensor: torch.tensor, target_length: int, default: int=0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    pads or truncates a given tensor along dim 0 to target_length with \"default\" as padding\n",
    "    \n",
    "    parameters:\n",
    "        suspected_tensor (torch.tensor): tensor to pad or truncate\n",
    "        target_length (int): target length of tensor\n",
    "        default (int): value to use for padding\n",
    "    \n",
    "    returns:\n",
    "        torch.tensor: tensor of proper length no matter what\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(suspected_tensor) < target_length:\n",
    "        # pad\n",
    "        suspected_tensor = torch.cat((torch.ones(target_length - len(suspected_tensor), suspected_tensor.shape[1], dtype=torch.float32, device=suspected_tensor.device) * default, suspected_tensor))\n",
    "    else:\n",
    "        # truncate\n",
    "        suspected_tensor = suspected_tensor[-target_length:]\n",
    "    \n",
    "    return suspected_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence_for_net(sentence: list, model: Word2Vec, context_length: int, flatten: bool=True, used_device: torch.device=run_device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    turns a sentence (list of strings) into a tensor that can be fed directly into the network\n",
    "    \n",
    "    parameters:\n",
    "        sentence (list): list of strings (words)\n",
    "        model (Word2Vec): model to use when encoding sentence\n",
    "        context_length (int): length of context to consider when encoding, should be same as network's\n",
    "    \n",
    "    returns:\n",
    "        torch.tensor: tensor of proper length no matter what\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode sentence to np.array\n",
    "    vectorized = vectorize_sentence(sentence, model)\n",
    "    vectorized_tensor = torch.from_numpy(vectorized).to(used_device).to(torch.float32)\n",
    "    \n",
    "    # pad or truncate\n",
    "    vectorized_tensor = pad_or_truncate(vectorized_tensor, context_length)\n",
    "    \n",
    "    if flatten:\n",
    "        # flatten to fit into first fc layer of the net\n",
    "        vectorized_tensor = vectorized_tensor.flatten()\n",
    "    \n",
    "    return vectorized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach_to_segment(start: np.ndarray, iterations: int, embeddings_model: Word2Vec, net: REAN, rand_seg_range: int=5) -> list:\n",
    "    start = torch.from_numpy(start).to(torch.float32).to(run_device).unsqueeze(0)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        start += net(start)\n",
    "    \n",
    "    return devectorize_sentence(start.detach().squeeze(0).cpu().numpy(), embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_lerp_steps(vectorized_sentence: np.ndarray, model: Word2Vec, steps: int) -> list[np.ndarray]:\n",
    "    random_point = np.random.uniform(np.min(vectorized_sentence), np.max(vectorized_sentence), (len(vectorized_sentence), vector_size))\n",
    "    \n",
    "    sentence_steps = []\n",
    "    \n",
    "    for indicies in range(steps):\n",
    "        sentence_steps.append(vectorized_sentence + (random_point - vectorized_sentence) * (indicies / steps))\n",
    "    \n",
    "    return sentence_steps[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REAN_dataset(Dataset):\n",
    "    def __init__(self, path, num_unique_examples, segment_size, embeddings_model, lerp_steps):\n",
    "        self.seek_start = 0\n",
    "        \n",
    "        self.segments = []\n",
    "        self.diffs = []\n",
    "        \n",
    "        for _ in tqdm(range(num_unique_examples)):\n",
    "            self.current_chunk, self.eof, self.seek_start = load_dataset_chunk(path, segment_size, self.seek_start)\n",
    "            \n",
    "            self.lerp_steps = get_sentence_lerp_steps(vectorize_sentence(self.current_chunk, embeddings_model), embeddings_model, lerp_steps)\n",
    "            \n",
    "            for self.current_step_idx in range(len(self.lerp_steps) - 1):\n",
    "                self.net_input = torch.from_numpy(self.lerp_steps[self.current_step_idx]).to(torch.float32).to(storage_device)\n",
    "                self.net_target = torch.from_numpy(self.lerp_steps[self.current_step_idx + 1]).to(torch.float32).to(storage_device)\n",
    "                \n",
    "                self.net_output = self.net_target - self.net_input\n",
    "                \n",
    "                self.segments.append(self.net_input)\n",
    "                self.diffs.append(self.net_output)\n",
    "            \n",
    "            if self.eof:\n",
    "                print(\"eof hit, early stop\")\n",
    "                print(f\"fluffed up size: {len(self.segments)}\")\n",
    "                return\n",
    "        \n",
    "        print(f\"fluffed up size: {len(self.segments)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.segments[index], self.diffs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98304/98304 [00:38<00:00, 2557.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluffed up size: 294912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:03<00:00, 1344.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluffed up size: 12288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = REAN_dataset(train_dataset_path, unique_examples_train, segment_size, embeddings_model, lerp_steps)\n",
    "test_dataset = REAN_dataset(test_dataset_path, unique_examples_test, segment_size, embeddings_model, lerp_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_graph = []\n",
    "test_loss_graph = []\n",
    "learning_rate_graph = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    epoch_train_loss = 0\n",
    "    for current_segment, target in train_loader:\n",
    "        # move batch to gpu\n",
    "        current_segment = current_segment.to(run_device)\n",
    "        target = target.to(run_device)\n",
    "        \n",
    "        # train batch\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = net(current_segment)\n",
    "        train_loss_value = loss(train_outputs, target)\n",
    "        train_loss_value.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect performance metrics\n",
    "        epoch_train_loss += train_loss_value.item()\n",
    "    \n",
    "    train_loss_graph.append(epoch_train_loss / len(train_loader))\n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "        epoch_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_current_segment, test_target in test_loader:\n",
    "                # move to gpu\n",
    "                test_current_segment = test_current_segment.to(run_device)\n",
    "                test_target = test_target.to(run_device)\n",
    "                \n",
    "                test_outputs = net(test_current_segment)\n",
    "                test_loss_value = loss(test_outputs, test_target)\n",
    "                epoch_test_loss += test_loss_value.item()\n",
    "                \n",
    "        test_loss_graph.append(epoch_test_loss / len(test_loader))\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Track the learning rate\n",
    "    learning_rate_graph.append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Real-time plotting\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_loss_graph, label='Train Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot testing loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(0, len(test_loss_graph) * 3, 3), test_loss_graph, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot learning rate\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(learning_rate_graph, label='Learning Rate')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(train_loss_graph)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_loss_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), 'no_attention_mech.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d91e4438f0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_loss_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'plinio', 'cronología', 'abnormally', 'nknown', 'illiquidity']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approach_to_segment(np.random.uniform(-5, 5, (segment_size, vector_size)), 3, embeddings_model, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
