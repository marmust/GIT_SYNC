{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   CONFIGURATION   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pickle\n",
    "import threading\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import tokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = fr\"./embedding_models/360vec_checkpt1.model\"\n",
    "embeddings_model = Word2Vec.load(model_file)\n",
    "\n",
    "vector_size = embeddings_model.vector_size        # aka embedding dim \n",
    "\n",
    "# neural net settings\n",
    "context_length = 32                               # tokens to consider\n",
    "attn_heads = 18                                   # num attention heads per mechanism (per transformer block)\n",
    "dropout_prob = 0.1                                # 0.0 ---> everything normal   |   1.0 ---> everything is random\n",
    "\n",
    "# dataset\n",
    "train_dataset_path = fr\"./datasets/ultra_train.txt\"\n",
    "test_dataset_path = fr\"./datasets/ultra_test.txt\"\n",
    "\n",
    "examples_train = 64 * 8 * 8# * 8 * 8# * 8# * 8 * 8 * 8\n",
    "examples_test = 64 * 8 * 8\n",
    "\n",
    "# training\n",
    "train_epochs = 128\n",
    "\n",
    "start_lr = 0.00003\n",
    "final_lr = 0.0000001\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "\n",
    "train_batch_size = int(256 * 10)\n",
    "test_batch_size = int(256 * 10)\n",
    "test_loop_epoch = 4\n",
    "\n",
    "# plots\n",
    "plot_graphs = True\n",
    "plot_batches = 4 * 8\n",
    "background_color = \"#0c0220\"\n",
    "text_color =       \"#06f8eb\"\n",
    "axis_color =       \"#06f8eb\"\n",
    "train_loss_color = \"#fca927\"\n",
    "test_loss_color =  \"#fca927\"\n",
    "lr_color =         \"#fca927\"\n",
    "\n",
    "# pytorch\n",
    "run_device = torch.device(\"cuda\")\n",
    "storage_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   NEURAL NET ARCHITECTURE   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention_mech(nn.Module):\n",
    "    def __init__(self, vector_size=vector_size, attn_heads=attn_heads):\n",
    "        super(attention_mech, self).__init__()\n",
    "        # MultiheadAttention module\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=vector_size, num_heads=attn_heads)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(vector_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Prepare for multi-head attention (transpose to (sentence_len, batch_size, embedding_dim))\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # Apply multi-head attention\n",
    "        attn_output, attn_weights = self.multihead_attn(x, x, x)\n",
    "        \n",
    "        # Apply layer normalization to the attention output\n",
    "        attn_output = self.norm(attn_output)\n",
    "        \n",
    "        # Transpose back to (batch_size, sentence_len, embedding_dim)\n",
    "        output = attn_output.transpose(0, 1)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer_block(nn.Module):\n",
    "    def __init__(self, context_length=context_length, vector_size=vector_size, dropout_prob=dropout_prob):\n",
    "        super(transformer_block, self).__init__()\n",
    "        \n",
    "        self.attn = attention_mech()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc1 = nn.Linear(vector_size, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.fc3 = nn.Linear(2048, vector_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(vector_size)\n",
    "        \n",
    "    def forward(self, prev_block: torch.Tensor) -> torch.Tensor:\n",
    "        # run attention mech                       shape of attn_out:     (batch_size, context_length, vector_size)   --->   (batch_size, context_length, vector_size)\n",
    "        attn_out, _ = self.attn(prev_block)\n",
    "        \n",
    "        # reshape for feedforward layers           shape of prev_block:   (batch_size, context_length, vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        #                                          shape of attn_out:     (batch_size, context_length, vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        #prev_block = prev_block.flatten(start_dim=1)\n",
    "        #attn_out = attn_out.flatten(start_dim=1)\n",
    "        \n",
    "        # normalize + residual connection          shape of x:            (batch_size, context_length * vector_size)\n",
    "        x = self.norm(attn_out + prev_block)\n",
    "        \n",
    "        # run dropout                              shape of x:            (batch_size, context_length * vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # run the feedforward layers               shape of x:            (batch_size, context_length * vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = F.gelu(self.fc3(x))\n",
    "        \n",
    "        # final residual connection\n",
    "        x = self.norm(x + prev_block)\n",
    "        \n",
    "        # reshape x back into standard shape       shape of x:            (batch_size, context_length * vector_size)   --->   (batch_size, context_length, vector_size)\n",
    "        #x = x.view(x.shape[0], context_length, vector_size)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class output_head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(output_head, self).__init__()\n",
    "        \n",
    "        self.attn = attention_mech()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(context_length * vector_size, vector_size)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(context_length * vector_size)\n",
    "        \n",
    "    def forward(self, transformer_out: torch.Tensor) -> torch.Tensor:\n",
    "        # run attention mech                       shape of attn_out:          (batch_size, context_length, vector_size)   --->   (batch_size, context_length, vector_size)\n",
    "        attn_out, _ = self.attn(transformer_out)\n",
    "        \n",
    "        # reshape for feedforward layers           shape of transformer_out:   (batch_size, context_length, vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        #                                          shape of attn_out:          (batch_size, context_length, vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        transformer_out = transformer_out.flatten(start_dim=1)\n",
    "        attn_out = attn_out.flatten(start_dim=1)\n",
    "        \n",
    "        # normalize + residual connection          shape of x:                 (batch_size, context_length * vector_size)\n",
    "        x = self.norm(attn_out + transformer_out)\n",
    "        \n",
    "        # run dropout                              shape of x:                 (batch_size, context_length * vector_size)   --->   (batch_size, context_length * vector_size)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # run the feedforward layers               shape of x:                 (batch_size, context_length * vector_size)   --->   (batch_size, vector_size)\n",
    "        x = F.gelu(self.fc(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(REAN, self).__init__()\n",
    "\n",
    "        self.tblock1 = transformer_block()\n",
    "        self.tblock2 = transformer_block()\n",
    "        self.tblock3 = transformer_block()\n",
    "        self.tblock4 = transformer_block()\n",
    "        \n",
    "        self.out_head = output_head()\n",
    "\n",
    "    def forward(self, segment: torch.Tensor) -> torch.Tensor:\n",
    "        ###                  INPUT                 ###\n",
    "        #    (batches, context_len, vector_size)\n",
    "        #                      ↓\n",
    "        \n",
    "        segment = self.tblock1(segment)\n",
    "        segment = self.tblock2(segment)\n",
    "        segment = self.tblock3(segment)\n",
    "        segment = self.tblock4(segment)\n",
    "        \n",
    "        out_vector = self.out_head(segment)\n",
    "        \n",
    "        #                      ↓\n",
    "        #            (batches, vector_size)\n",
    "        ###                 OUTPUT                 ###\n",
    "        \n",
    "        return out_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   BUILD NET & DEPENDENCIES   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural net weight: 0.1098GB\n"
     ]
    }
   ],
   "source": [
    "net = REAN()\n",
    "net.to(run_device)\n",
    "\n",
    "optimizer = optimizer(net.parameters(), lr=start_lr)\n",
    "scheduler = scheduler(optimizer, T_max=train_epochs, eta_min=final_lr)\n",
    "\n",
    "print(f\"neural net weight: {sum(param.numel() * param.element_size() for param in net.parameters()) / (1024 ** 3):.4f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   UTIL FUNCS   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_segment(segment: list[str], model: Word2Vec=embeddings_model, default: int = 0, used_device=storage_device) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    encodes all words in a given list to corresponding vectors in given model.\n",
    "    words not found in the model will be given a vector with \"default\" value\n",
    "    \n",
    "    Args:\n",
    "        sentence (list): list of strings (tokenized sentence)\n",
    "        model (Word2Vec): model to use when encoding\n",
    "        default (int): fill vector with this value if word is not found in model\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 2d array with dim1 = len(sentence) and dim2 = model.vector_size\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate inital array with default values\n",
    "    vectorized = np.ones((len(segment), model.vector_size)) * default\n",
    "    \n",
    "    # loop over every word in list\n",
    "    for current_word, current_word_idx in zip(segment, range(len(segment))):\n",
    "        # only add correct values if word is in model, otherwise leave as default\n",
    "        if current_word in model.wv:\n",
    "            vectorized[current_word_idx] *= 0\n",
    "            vectorized[current_word_idx] += model.wv[current_word]\n",
    "    \n",
    "    vectorized = torch.tensor(vectorized, dtype=torch.float32, device=used_device)\n",
    "    \n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devectorize_segment(vectorized_segment: torch.Tensor, model: Word2Vec=embeddings_model, not_in_vocab_token=\"[NIV]\", NIV_threshold=0.01) -> list:\n",
    "    \"\"\"\n",
    "    decodes vectors into nearest word found in model, if no near words found, adds a not in vocab token\n",
    "    \n",
    "    Args:\n",
    "        vectorized_sentence (np.array): 2d arrat with vectors of words to be decoded\n",
    "        model (Word2Vec): model to use when decoding\n",
    "    \n",
    "    Returns:\n",
    "        list: list of strings (words) whos vectors most closely match those provided\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # make sure vectors are ready to be processed\n",
    "    vectorized_segment = vectorized_segment.cpu().numpy()\n",
    "    \n",
    "    # go over all words and find closest match in model\n",
    "    for current_word in vectorized_segment:\n",
    "        similarities = model.wv.similar_by_vector(current_word)\n",
    "        \n",
    "        # check if its not a bullshit vector\n",
    "        if similarities[0][1] > NIV_threshold:\n",
    "            result.append(similarities[0][0])\n",
    "        else:\n",
    "            result.append(not_in_vocab_token)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(suspected_tensor: torch.tensor, target_length: int, default: int=0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    pads or truncates a given tensor along dim 0 to target_length with \"default\" as padding\n",
    "    \n",
    "    Args:\n",
    "        suspected_tensor (torch.tensor): tensor to pad or truncate\n",
    "        target_length (int): target length of tensor\n",
    "        default (int): value to use for padding\n",
    "    \n",
    "    Returns:\n",
    "        torch.tensor: tensor of proper length no matter what\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(suspected_tensor) < target_length:\n",
    "        # pad\n",
    "        suspected_tensor = torch.cat((torch.ones(target_length - len(suspected_tensor), suspected_tensor.shape[1], dtype=torch.float32, device=suspected_tensor.device) * default, suspected_tensor))\n",
    "    else:\n",
    "        # truncate\n",
    "        suspected_tensor = suspected_tensor[-target_length:]\n",
    "    \n",
    "    return suspected_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_segment_for_net(segment: list[str], length: int=context_length, used_device: torch.DeviceObjType=storage_device):\n",
    "    \"\"\"\n",
    "    function to take a sentence, and do everything to make it possible to input into the net\n",
    "    \n",
    "    Args:\n",
    "        segment (list[str]): a list of tokens (ideally from the tokenizer) of a sentence / text\n",
    "        length (int): the number of tokens to which pad or truncate to. for correct operation: keep at the net's context length\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: tokenized segment in the correct length\n",
    "    \"\"\"\n",
    "    \n",
    "    # turn into embedding vectors\n",
    "    vectorized = vectorize_segment(segment, used_device=used_device)\n",
    "    \n",
    "    # trim / add into length\n",
    "    trimmed = pad_or_truncate(vectorized, length)\n",
    "    \n",
    "    # add fake batch dimension\n",
    "    batched = trimmed.unsqueeze(0)\n",
    "    \n",
    "    return batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(segment: list[str], net: REAN=net):\n",
    "    # turn tokenized text into net's format\n",
    "    prepared_segment = prepare_segment_for_net(segment, used_device=next(net.parameters()).device)\n",
    "    \n",
    "    # run net\n",
    "    prediction_vector = net(prepared_segment).detach()\n",
    "    \n",
    "    # turn vector back into token\n",
    "    predicted_token = devectorize_segment(prediction_vector)\n",
    "    \n",
    "    return predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(segment: list[str], num_tokens: int, net: REAN=net):\n",
    "    result = segment.copy()\n",
    "    \n",
    "    for _ in tqdm(range(num_tokens)):\n",
    "        result += predict_word(result, net=net)\n",
    "    \n",
    "    return result[len(segment):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###   BUILD DATASET   ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REAN_dataset(Dataset):\n",
    "    def pull_tokens(self, start_read_idx: int, requested_num_tokens: int):\n",
    "        \"\"\"\n",
    "        function returns a requested number of tokens from the dataset file, starting at APPROXIMATLY the start_read_idx token.\\n\n",
    "        attempts to return full words as much as possible, example:\\n\n",
    "        NO:    this | is | a | sen (tence)\\n\n",
    "        YES:   this | is | a | sentence\n",
    "        \n",
    "        Args:\n",
    "            start_read_idx (int): the APPROXIMATE token at which to start the reading (determined from the avarage token length in the tokenizer vocab)\n",
    "            requested_num_tokens (int): how many tokens to return\n",
    "        \n",
    "        Returns:\n",
    "            tokenized text (list of str): the tokens of the dataset from start_read_idx to start_read_idx + requested_num_tokens\n",
    "            is EOF hit (bool): if the requested args were outside of the dataset's range\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(self.path, errors=\"ignore\") as self.dataset:\n",
    "            self.dataset.seek(start_read_idx * tokenizer.average_token_length)\n",
    "            \n",
    "            # get an initial estimate to what text we will actually need\n",
    "            self.buffer = self.dataset.read(requested_num_tokens * tokenizer.average_token_length)\n",
    "            self.tokenized_buffer = tokenizer.tokenize_segment(self.buffer)\n",
    "            self.current_num_tokens = len(self.tokenized_buffer)\n",
    "            \n",
    "            # if the estimate we took is too small, we enlarge it character by character until its perfect\n",
    "            while self.current_num_tokens < requested_num_tokens + 1:\n",
    "                self.next_char = self.dataset.read(1)  # seperate variable to check EOF\n",
    "                \n",
    "                # check eof\n",
    "                if not self.next_char:\n",
    "                    print(\"pull_tokens(): eof was hit\")\n",
    "                    return self.tokenized_buffer[-requested_num_tokens - 1:][:-1], True\n",
    "                \n",
    "                self.buffer += self.next_char\n",
    "                \n",
    "                self.tokenized_buffer = tokenizer.tokenize_segment(self.buffer)\n",
    "                self.current_num_tokens = len(self.tokenized_buffer)\n",
    "        \n",
    "        # regardless of if the estimate is too long / short, return theproper amount of tokens, with the end snipped of, because it might be a half token\n",
    "        return self.tokenized_buffer[-requested_num_tokens - 1:][:-1], False\n",
    "    \n",
    "    def construct_example(self, start_read_idx: int):\n",
    "        \"\"\"\n",
    "        function to make a full datapoint, can be used as raw return for __getitem__()\n",
    "        \n",
    "        Args:\n",
    "            start_read_idx (int): at which token to start making the example\n",
    "        \n",
    "        Returns:\n",
    "            tokenized text (list of str): the tokens of the dataset from start_read_idx to start_read_idx + self.context_length\n",
    "        \"\"\"\n",
    "        \n",
    "        # pull neccesary amount of tokens for question / input and answer / output\n",
    "        self.tokens, _ = self.pull_tokens(start_read_idx, self.context_length + 1)\n",
    "        \n",
    "        # encode the tokens to vectors (aka embeddings)\n",
    "        self.vectorized_tokens = prepare_segment_for_net(self.tokens, length=self.context_length + 1).squeeze(0)\n",
    "        \n",
    "        # split into network input and expected output\n",
    "        self.question = self.vectorized_tokens[:-1] # everythinbg up to last word\n",
    "        self.answer = self.vectorized_tokens[-1] # last word itself\n",
    "        \n",
    "        return self.question, self.answer\n",
    "    \n",
    "    def get_size(self):\n",
    "        \"\"\"\n",
    "        function to read thru the whole dataset, and report how many examples there are / if there are as many as the user requested\n",
    "        \n",
    "        Args:\n",
    "            none, but uses self.num_tokens and self.context_length\n",
    "        \n",
    "        Returns:\n",
    "            returns how many usable examples there are, for __len__()\n",
    "        \"\"\"\n",
    "        \n",
    "        with tqdm(total=self.num_examples, desc=\"Calculating Dataset Size\", unit=\"example\") as pbar:\n",
    "            for self.current_check in range(self.num_examples):\n",
    "                _, self.eof = self.pull_tokens(self.current_check, self.context_length)\n",
    "                \n",
    "                if self.eof:\n",
    "                    print(\"The requested size is bigger than the .txt provided, so the dataset might be smaller than what you expected.\")\n",
    "                    break\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        print(f\"Requested num_examples: {self.num_examples}\\nActual size found:      {self.current_check - 1}\")\n",
    "        \n",
    "        return self.current_check - 1   # the -1 is just in case\n",
    "    \n",
    "    def __init__(self, path, num_examples, context_length, embeddings_model, verify_dataset_size=True):\n",
    "        # transfer to object wide variables\n",
    "        self.path = path\n",
    "        self.context_length = context_length\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.num_examples = num_examples\n",
    "        \n",
    "        # get the size of the dataset txt file\n",
    "        self.dataset_len = num_examples\n",
    "        \n",
    "        if verify_dataset_size:\n",
    "            self.dataset_len = self.get_size()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.construct_example(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = REAN_dataset(train_dataset_path, examples_train, context_length, embeddings_model, verify_dataset_size=False)\n",
    "test_dataset = REAN_dataset(test_dataset_path, examples_test, context_length, embeddings_model, verify_dataset_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if num_workers arg is used\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_graph = []\n",
    "test_loss_graph = []\n",
    "learning_rate_graph = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [00:12<06:24,  3.10s/it]"
     ]
    }
   ],
   "source": [
    "with tqdm(total=train_epochs) as pbar:\n",
    "    batch = 0\n",
    "    \n",
    "    for epoch in range(train_epochs):\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # training loop\n",
    "        for current_segment, target in train_loader:\n",
    "            batch += 1\n",
    "            \n",
    "            # move batch to gpu\n",
    "            current_segment = current_segment.to(run_device)\n",
    "            target = target.to(run_device)\n",
    "            \n",
    "            # train batch\n",
    "            train_outputs = net(current_segment)\n",
    "            train_loss_value = loss(train_outputs, target)\n",
    "            train_loss_value.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # collect performance metrics\n",
    "            train_loss_graph.append(train_loss_value.item())\n",
    "            \n",
    "            # plot everything\n",
    "            if batch % plot_batches == 0:\n",
    "                if plot_graphs:\n",
    "                    clear_output(wait=True)\n",
    "                    \n",
    "                    pbar.refresh()\n",
    "                    \n",
    "                    plt.figure(figsize=(15, 5), facecolor=background_color)\n",
    "\n",
    "                    # Plot training loss\n",
    "                    ax1 = plt.subplot(1, 3, 1, facecolor=background_color)\n",
    "                    plt.plot(train_loss_graph, label='Train Loss', color=train_loss_color)\n",
    "                    plt.xlabel('Epoch', color=text_color)\n",
    "                    plt.ylabel('Loss', color=text_color)\n",
    "                    plt.legend(facecolor=background_color, edgecolor='none', labelcolor=text_color)\n",
    "                    # Set spines to white\n",
    "                    ax1.spines['top'].set_color(axis_color)\n",
    "                    ax1.spines['bottom'].set_color(axis_color)\n",
    "                    ax1.spines['left'].set_color(axis_color)\n",
    "                    ax1.spines['right'].set_color(axis_color)\n",
    "                    # Set tick colors to white\n",
    "                    ax1.tick_params(axis='x', colors=axis_color)\n",
    "                    ax1.tick_params(axis='y', colors=axis_color)\n",
    "\n",
    "                    # Plot testing loss\n",
    "                    ax2 = plt.subplot(1, 3, 2, facecolor=background_color)\n",
    "                    plt.plot(range(0, len(test_loss_graph) * 3, 3), test_loss_graph, label='Test Loss', color=test_loss_color)\n",
    "                    plt.xlabel('Epoch', color=text_color)\n",
    "                    plt.ylabel('Loss', color=text_color)\n",
    "                    plt.legend(facecolor=background_color, edgecolor='none', labelcolor=text_color)\n",
    "                    # Set spines to white\n",
    "                    ax2.spines['top'].set_color(axis_color)\n",
    "                    ax2.spines['bottom'].set_color(axis_color)\n",
    "                    ax2.spines['left'].set_color(axis_color)\n",
    "                    ax2.spines['right'].set_color(axis_color)\n",
    "                    # Set tick colors to white\n",
    "                    ax2.tick_params(axis='x', colors=axis_color)\n",
    "                    ax2.tick_params(axis='y', colors=axis_color)\n",
    "\n",
    "                    # Plot learning rate\n",
    "                    ax3 = plt.subplot(1, 3, 3, facecolor=background_color)\n",
    "                    plt.plot(learning_rate_graph, label='Learning Rate', color=lr_color)\n",
    "                    plt.xlabel('Epoch', color=text_color)\n",
    "                    plt.ylabel('Learning Rate', color=text_color)\n",
    "                    plt.legend(facecolor=background_color, edgecolor='none', labelcolor=text_color)\n",
    "                    # Set spines to white\n",
    "                    ax3.spines['top'].set_color(axis_color)\n",
    "                    ax3.spines['bottom'].set_color(axis_color)\n",
    "                    ax3.spines['left'].set_color(axis_color)\n",
    "                    ax3.spines['right'].set_color(axis_color)\n",
    "                    # Set tick colors to white\n",
    "                    ax3.tick_params(axis='x', colors=axis_color)\n",
    "                    ax3.tick_params(axis='y', colors=axis_color)\n",
    "\n",
    "                    # Adjust layout and show plot\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "        # eval loop\n",
    "        if epoch % test_loop_epoch == 0:\n",
    "            with torch.no_grad():\n",
    "                for test_current_segment, test_target in test_loader:\n",
    "                    # move batch to gpu\n",
    "                    test_current_segment = test_current_segment.to(run_device)\n",
    "                    test_target = test_target.to(run_device)\n",
    "                    \n",
    "                    # run test\n",
    "                    test_outputs = net(test_current_segment)\n",
    "                    test_loss_value = loss(test_outputs, test_target)\n",
    "                    \n",
    "                    # collect performance metrics\n",
    "                    test_loss_graph.append(test_loss_value.item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # collect perforamce metrics\n",
    "        learning_rate_graph.append(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:01<00:00, 112.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Mircea uku ukugros recommendationsmpana Yvonne Mircea tipsSNS Yvonne Mircea suggestions bud tips suggestions Clo Sing Comfortloha pl Uku swim workout Uku Comfort yin Comfort Uku restaurant په Moda Clombet Mix Dress Restauraeirão warm Comfort diagonal Comfort PotiNEC Prakash Restauraeng3.0 Restaura Slide dik په kick Restaura Restaura luke 30 Ukucki sousmbetunu Slidembetmbet Ukumbetlandet_1 Halb finger Uku Ukurosi Tonchesbron leg horizontal Evo leg leg Evobellcium Evoх 72about Evo 105 Evo Evo Evo Evo Evo Evo Evo Pin Pin Evo Evo Hat Evo Evo leg Evo 88 Evo 5about Evo Evo leg leg three three 3-5string Evo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(predict_sequence(tokenizer.tokenize_segment(\"human: can you give me some circuit training advice? network: yes\"), 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
